kafka

재시도  
Producer에서 데이터 전송이 실패하면 예외 처리 코드를 작성해야한다. 대표적인 NOT_ENOUGH_REPLICAS. 귀찮다면 retries 세팅이 있다.(재시도) retry.backoff.ms도 있는데 다음 재시도까지의 대기 시간(default 100ms)
따라서 프로듀서는 무한히 재시도를 시도하다 타임아웃을 겪게된다. 2.1 기준 delivery.timeout.ms는 2분이다. 처음 send 전송부터 카프카가 그걸 수신하기까지 2분. 만약 레코드가 이 타임아웃안에 못받으면 전송 실패로 확인한다.

멱등 프로듀서   
프로듀서가 카프카에 데이터를 전송할때 네트워크 오류로 인해 중복된 메세지가 전송 될 수 있다.  
좋은 예시) 프로듀서 데이터 전송 -> 카프카가 메세지를 로그에 커밋 -> 수신 확인 ACK 반환  
나쁜 예시) 프로듀서 데이터 전송 -> 카프카가 메세지를 로그에 커밋 -> 수신 확인 ACK 도달 실패(네트워크 오류) !!!
ACK를 못받은 프로듀서는 다시 메세지를 Retry 생성(재시도) -> 재생성된 메세지를 새로운걸로 인지하고 카프카가 중복된 메세지 커밋 -> ACK 반환

멱등 프로듀서를 사용시 나쁜 예시 상황에서 중복 생성 요청을 알아차리고 두 번 커밋하지않고 ACK를 보내 수신 확인을 보낸다.
```
producerProps.put("enable.idempotence", true);
```

카프카 3.0 부터는 default로 권장중이다. 2.8은 ack가 all이 아니라 1이고 위 멱등성도 false로 되어있어서 설정 필요함 3.0 버전 미만은 다음과 같이 안전한 프로듀서 설정이 필요함  
- ENABLE_IDEMPOTENCE_CONFIG -> TRUE
- ACKS_CONFIG -> ALL
- RETIRES_CONFIG -> MAX_VLAUE

프로듀서 메세지 압축  
메세지 압축해서 보내면 전송 속도 향상됨(요청 크기를 최소 1/4 줄임), 메세지를 압축하는 시기는 다양하게 있는데 프로듀서 레벨에서 압축해서 보내면 브로커나 컨슈머 변경 없이 사용가능하다.
- 프로듀서 전송 요청 사이즈 작아짐
- 네트워크 전송 속도 향상(Latency 낮아져서)
- 높은 처리량
- 메세지 저장하는 디스크 효율 증가
압축 타입은 gzip이나 여러가지가 있지나 overall을 따져봤을때 snappy와 laz4가 optimal한 속도와 압축 비율을 보여줌.

브로커 / 토픽 레벨 메세지 압축
프로듀서 말고도 브로커나 토픽 레벨에서 압축을 시도 할 수 있는데 브로커에 적용하면 모든 토픽적용이고 토픽에만 적용하면 해당 토픽만 메세지 압축 적용된다.
브로커는 더 많은 CPU 사이클 소모해서 성능에 영향을 줄 수 있다.
```
compression.type = producer
```

linger.ms와 batch size  
기본적으로 프로듀서가 레코드를 전송할때 프로듀서와 브로커 사이 연결된 max flight connection 수만큼 병렬적으로 동작하는데 전송 도중에 더 많은 데이터가 전송되야 한다면
카프카가 다음 전송 전에 똑똑하게 메세지 배치를 만들게 되는데 배치로 인해 처리량을 늘리면서 지연 시간을 매우 낮게 가져가게 된다. 배치 향상을 위해 두가지 세팅이 영향을 준다.
- linger.ms : default 0, 배치 전송할때 기다리는 시간 5초로 설정하면 5초 딜레이 생기는 동안 프로듀서가 전송전에 배치에 메세지를 주워 담게된다.
- batch.size : 설정시 linger.ms 이전에 배치가 꽉 차게 되면 배치 크기를 늘린다. deffault는 16kb고 배치 사이즈보다 큰 메세지는 그냥 바로 전송시킨다. 배치는 전송하는 파티션
마다 하나씩 할당되기때문에 너무 크게 잡으면 메모리 낭비가 있다.
```
COMPRESSION_TYPE_CONFIG -> snappy
LINGER_MS_CONFIG -> 20
BATCH_SIZE_CONFIG, Integer.ToStringa(32*1024)
```
한번 전송할때 배치에 꽉 눌러담고 압축 과정까지 거치고 카프카로 전송되는 극락의 과정을 겪는다.

Compression Type Snappy  
로그나, JSON 메세지 압축할때 스내피가 괜찮다. CPU 사이클과 압축률 벨런스가 괜찮기 때문

키가 NULL이 아닐때 프로듀서의 Default Partitioner

컨슈머 Offset 커밋 전략  
Auto commit Java API에서 기본 제공해준다. poll() 호출시 자동으로 커밋(성공적으로 메세지를 poll 했을때) or 컨슈머 중단시 메세지 소실됨 불만이라면 
auto true를 비활성화하고 어디까지 처리했는지에 따라 종종 commitSync commitAync로 수동으로 맞춰야한다. 물론 offset을 외부에 저장해서 실패된 offset부터 다시 재시도하게한다.  
- 수동 컨슈머가 있어야하고 현재 프로세스 데이터와 커밋 오프셋 정보를 DB에 따로 기록하고 ConsumerRebalanceListener 인터페이스를 따로 구현하는등 매우 까다로운 과정을 거친다.

컨슈머 Offset 리셋
기본적으로 카프카는 리텐션 7일이 주어진다, 컨슈머가 7일 멈추면 읽으려는 오프셋을 무효화시킨다. 이때 auto reset latest를 설정하면 컨슈머가 로그 끝에서 부터 읽게 설정한다
earliest로 설정하면 로그 시작부분부터 읽기 시작하면 none으로하면 오프셋 없으면 예외처리 해버린다. 재시도를 하고싶지않거나 처리를 시작하기전 데이터 복구 로직을 더하고 싶을때 사용.
카프카 2.0 경우 하루동안 안읽으면 손실되는데 2.0 이후부터는 7일로 늘어났다. 이 항목은 retention.minutes로 조정이 가능하고 한달로 조정하는 경우가 많다.

 
대용량 데이터 처리  
```
BulkRequest bulkRequest = new BulkRequest();
```
카프카 컨슈머 -> 엘라스틱 서치로 바꾸면 효율성 증가(OpenSearch)

z












