kafka

재시도  
Producer에서 데이터 전송이 실패하면 예외 처리 코드를 작성해야한다. 대표적인 NOT_ENOUGH_REPLICAS. 귀찮다면 retries 세팅이 있다.(재시도) retry.backoff.ms도 있는데 다음 재시도까지의 대기 시간(default 100ms)
따라서 프로듀서는 무한히 재시도를 시도하다 타임아웃을 겪게된다. 2.1 기준 delivery.timeout.ms는 2분이다. 처음 send 전송부터 카프카가 그걸 수신하기까지 2분. 만약 레코드가 이 타임아웃안에 못받으면 전송 실패로 확인한다.

멱등 프로듀서   
프로듀서가 카프카에 데이터를 전송할때 네트워크 오류로 인해 중복된 메세지가 전송 될 수 있다.  
좋은 예시) 프로듀서 데이터 전송 -> 카프카가 메세지를 로그에 커밋 -> 수신 확인 ACK 반환  
나쁜 예시) 프로듀서 데이터 전송 -> 카프카가 메세지를 로그에 커밋 -> 수신 확인 ACK 도달 실패(네트워크 오류) !!!
ACK를 못받은 프로듀서는 다시 메세지를 Retry 생성(재시도) -> 재생성된 메세지를 새로운걸로 인지하고 카프카가 중복된 메세지 커밋 -> ACK 반환

멱등 프로듀서를 사용시 나쁜 예시 상황에서 중복 생성 요청을 알아차리고 두 번 커밋하지않고 ACK를 보내 수신 확인을 보낸다.
```
producerProps.put("enable.idempotence", true);
```

카프카 3.0 부터는 default로 권장중이다. 2.8은 ack가 all이 아니라 1이고 위 멱등성도 false로 되어있어서 설정 필요함 3.0 버전 미만은 다음과 같이 안전한 프로듀서 설정이 필요함  
- ENABLE_IDEMPOTENCE_CONFIG -> TRUE
- ACKS_CONFIG -> ALL
- RETIRES_CONFIG -> MAX_VLAUE

프로듀서 메세지 압축  
메세지 압축해서 보내면 전송 속도 향상됨(요청 크기를 최소 1/4 줄임), 메세지를 압축하는 시기는 다양하게 있는데 프로듀서 레벨에서 압축해서 보내면 브로커나 컨슈머 변경 없이 사용가능하다.
- 프로듀서 전송 요청 사이즈 작아짐
- 네트워크 전송 속도 향상(Latency 낮아져서)
- 높은 처리량
- 메세지 저장하는 디스크 효율 증가
압축 타입은 gzip이나 여러가지가 있지나 overall을 따져봤을때 snappy와 laz4가 optimal한 속도와 압축 비율을 보여줌.

브로커 / 토픽 레벨 메세지 압축
프로듀서 말고도 브로커나 토픽 레벨에서 압축을 시도 할 수 있는데 브로커에 적용하면 모든 토픽적용이고 토픽에만 적용하면 해당 토픽만 메세지 압축 적용된다.
브로커는 더 많은 CPU 사이클 소모해서 성능에 영향을 줄 수 있다.
```
compression.type = producer
```

linger.ms와 batch size  
기본적으로 프로듀서가 레코드를 전송할때 프로듀서와 브로커 사이 연결된 max flight connection 수만큼 병렬적으로 동작하는데 전송 도중에 더 많은 데이터가 전송되야 한다면
카프카가 다음 전송 전에 똑똑하게 메세지 배치를 만들게 되는데 배치로 인해 처리량을 늘리면서 지연 시간을 매우 낮게 가져가게 된다. 배치 향상을 위해 두가지 세팅이 영향을 준다.
- linger.ms : default 0, 배치 전송할때 기다리는 시간 5초로 설정하면 5초 딜레이 생기는 동안 프로듀서가 전송전에 배치에 메세지를 주워 담게된다.
- batch.size : 설정시 linger.ms 이전에 배치가 꽉 차게 되면 배치 크기를 늘린다. deffault는 16kb고 배치 사이즈보다 큰 메세지는 그냥 바로 전송시킨다. 배치는 전송하는 파티션
마다 하나씩 할당되기때문에 너무 크게 잡으면 메모리 낭비가 있다.
```
COMPRESSION_TYPE_CONFIG -> snappy
LINGER_MS_CONFIG -> 20
BATCH_SIZE_CONFIG, Integer.ToStringa(32*1024)
```
한번 전송할때 배치에 꽉 눌러담고 압축 과정까지 거치고 카프카로 전송되는 극락의 과정을 겪는다.

Compression Type Snappy  
로그나, JSON 메세지 압축할때 스내피가 괜찮다. CPU 사이클과 압축률 벨런스가 괜찮기 때문

키가 NULL이 아닐때 프로듀서의 Default Partitioner

컨슈머 Offset 커밋 전략  
Auto commit Java API에서 기본 제공해준다. poll() 호출시 자동으로 커밋(성공적으로 메세지를 poll 했을때) or 컨슈머 중단시 메세지 소실됨 불만이라면 
auto true를 비활성화하고 어디까지 처리했는지에 따라 종종 commitSync commitAync로 수동으로 맞춰야한다. 물론 offset을 외부에 저장해서 실패된 offset부터 다시 재시도하게한다.  
- 수동 컨슈머가 있어야하고 현재 프로세스 데이터와 커밋 오프셋 정보를 DB에 따로 기록하고 ConsumerRebalanceListener 인터페이스를 따로 구현하는등 매우 까다로운 과정을 거친다.

컨슈머 Offset 리셋
기본적으로 카프카는 리텐션 7일이 주어진다, 컨슈머가 7일 멈추면 읽으려는 오프셋을 무효화시킨다. 이때 auto reset latest를 설정하면 컨슈머가 로그 끝에서 부터 읽게 설정한다
earliest로 설정하면 로그 시작부분부터 읽기 시작하면 none으로하면 오프셋 없으면 예외처리 해버린다. 재시도를 하고싶지않거나 처리를 시작하기전 데이터 복구 로직을 더하고 싶을때 사용.
카프카 2.0 경우 하루동안 안읽으면 손실되는데 2.0 이후부터는 7일로 늘어났다. 이 항목은 retention.minutes로 조정이 가능하고 한달로 조정하는 경우가 많다.

 
대용량 데이터 처리  
```
BulkRequest bulkRequest = new BulkRequest();
```
카프카 컨슈머 -> 엘라스틱 서치로 바꾸면 효율성 증가(OpenSearch)

파티션 카운트 & 레플리케이션  
토픽을 생성할때 가장 중요한 두가지 요소, 시간이 지나서 변경하거나 혹은 바로 변경하면 시스템 성능과 지속성에 영향을 주기 때문이다.
- 토픽 라이프사이클이 돌아가는중 파티션의 카운트를 늘린다면?
key ordering이 무너지면서 키 순서 보장이 되지 않는다.
- 토픽 라이프사이클이 돌아가는중 레플레케이션을 늘린다면?
네트워크 통신 증가, 클러스터 부하 증가에 따른 성능 저하 발생

토픽별 파티션 수를 정하는 가이드라인(백억짜리 질문)  
브로커가 6개 미만인 작은 클러스터라면 브로커 개수에 3을 곱해라  
브로커가 12개를 초과(큰 클러스터)는 브로커 개수에 2를 곱해라  
이보다 증가시키려면 병렬 결과를 끌어올려야되면 올리고 만약 향후 2년안에 요청이 폭발할꺼라고 확신이들면 처음부터 파티션 많이 두는게 맞다   
각 카프카 클러스터는 어떤 머신에서 돌아가느냐에따라 성능이 전부 다르기때문에 무조건 테스트를 필수적으로 진행해야한다.

레플리케이션 수  
최소 2개, 운영시 3개, 맥시멈 4개    
많으면 가용성 증가하지만 시스템의 디스크 많이 쓰게되고 latency가 ack all이라 길어진다  
3개로하고 만약 레플리케이션 성능 문제라면 그건 레플리케이션 줄이는 선택이 아니라 더 성능 좋은 브로커가 필요한거다

꿀잼 리얼월드 예시
TV 드라마 영화 플랫폼
요구사항
- 시청 중이던 영상을 보던 위치에서 다시 보기
- 실시간으로 유저 프로필 만들기
- 실시간으로 다음 시청 영상 추천하기
- 관련 데이터는 분석 저장소(DB)에 저장하기

카프카 클러스터 셋업
각 다른 데이터 센터에 분산시킬때(주키퍼 사용시) 최소 3개 클러스터가 권장된다 aws 기준으로
us-east-1a (aws) 
- zookeeper1
- kafka broker1
- kafka broker4

us-east-1b (aws) 
- zookeeper2
- kafka broker2
- kafka broker5

us-east-1c (aws) 
- zookeeper3
- kafka broker3
- kafka broker6

클러스터 셋업이 간단한 작업이 아니다, 각 주키퍼, 브로커들을 서버별로 싱크 맞춰야할게 많다 
 예를 들어) DNS 관리, 스케일링, 장애 발생시 백업 
외에도 카프카의 기능들을 모두 숙지하고 있어야하고 모니터링또한 필수적으로 구성해야한다. 
 Amazon MSK, cLOUDFLUENT cLOUD, aIVEN, cLOUDkARAFKA, iNSTACLUSTER, Upstash Etc  
위 도구들이 업데이트, 모니터링, 셋업 작업을 거들어 주기는 한다.

브로커 몇개 사용할건가?  
쓰루풋, 데이터 리텐션 기간, 레플리케이션 개수에 따라서 테스트해가며 결졍해야한다.

브로커 설정 뿐만 아니라 카프카 커텍트 클러스터도 구성해야되고 스키마(최소 2개), 어드민 작업을 위한 자동화 UI Tool도 필수  

모니터링  
클러스터링 구성이후 모니터링은 JMX를 통해서 볼 수 있다 모든 카프카 지표가 노출되는 장소이다.  
JMX로 어떤 브로커에서 문제가 생기는지 트러블 지점을 파악할 수 있다.
자주 사용되는 카프카 지표툴
- ELK(ElasticSearch + Kibana)
- Datadog
- NewRelic
- Promotheus

모니터링중 중요하게 봐야할 포인트들이 몇가지가 있다.
- URP, Under Replicated Partition : ISR에 문제가 있는 파티션 개수를 나타낸다.(파티션 싱크가 안되고 있다는 의미), URP가 높다면 시스템 부하가 크다는걸 알 수 있다.
- Request Handlers : 네트워크, IO 스레드 지표인데 브로커의 활용도를 나타낸다. 이게 높다면 더 많은 브로커가 필요하다는 의미
- Request Timing : 높을수록 레이턴시를 낮춰야함

카프카 운영시 필요한 기술들
- 브로커 롤링 재시작하기
- 설정 정보 업데이트(브로커, 토픽)
- 클러스터 전반에 걸친 파티션 균형 다시 맞추기(리벨런싱)
- 레플리케이션 증설하기 낮추기
- 브로커 추가하기, 대체하기, 제거하기
- 다운타임 없이 카프카 클러스터 덥데이트하기

카프카 멀티 클러스터와 복제  
카프카가 하나의 지역에서만 잘 운용하는것보다 데이터센터의 위치에 맞게 카프카 클러스터를 두는 형태가 일반적이다(IDC 이중화) 그 가운데 어느 정도는 레플리카를 만들어 둘거고 
레플리케이션은 결국 컨슈머와 프로듀서의 코어다. 레플리케이션을 위해 제일 많이 사용되는 툴들은 밑에 리스트가 있다.
- Mirror Makser 2 : 클러스터의 데이터를 다른 클러스터로 복제한다.
- Flink : Netflix에서는 내부에서 Flink라는 직접 만든 기술을 사용해서 정보를 직접 write 한다.
- uReplicator : 우버에서는 Mirror Maker 1의 성능 개선을 위해 uReplicator를 만들어서 사용중.
Mirror Maker 2 써보고 불만이면 직접 만들어야되는데 상당히 어려운 작업이 될것이다.

Active/Active 복제
각자 로컬 범위에서 작동하는 프로듀서와 컨슈머 클러스터 쌍으로 쓰기 작업이 가능해서 양방향 복제가 가능한 방법
장점
- 유저가 가까운 데이터센터를 이용할 수 있음, 네트워크 레이턴시를 낮춰 성능 측면에서 장점
- 한 데이터센터에 장애가 생겨도 남은 클러스터의 프로듀서가 데이터를 생성할 수 있다 물론 지연이 발생하지만 카프카 사용 가능
단점
- 데이터를 읽을 때 충돌을 피해야한다는점(데이터가 양방향 싱크되기 때문)

Active/Passive 복제
한쪽 클러스터가 Active되고 그 클러스터가 복제되는 방식을 말한다. 복제된 클러스터를 수동 클러스터라고 하는데 쓰기가 불가능하기 때문이다.
장점
- 구성이 쉽다, 주 클러스터가 하나고 나머지는 원하는곳 어디에나 복제하기 때문이다.
- 데이터 접근과 충돌같은 복잡성을 걱정할 필요가 없다.
- 클라우드 마이그레이션도 쉬움, 클러스터 전체를 복사해서 그대로 클라우드에 올리면 완료
단점
- 낭비, 좋은 클러스터 하나를 읽기로만 쓰니까 아깝다.
- 메인 클러스터에 장애가 생겨 페일오버 처리를 해야할 때 데이터 손실이나 중복이 발생하는 것도 문제이다.
