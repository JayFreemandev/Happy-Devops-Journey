**카프카의 특징**

토픽에 메세지를 publish하고  subscribe구조

토픽은 병렬 처리를 위해 파티션 단위로 구성

파티션은 안정성을 위해 레플리카로 복제 구성

**Stateful 시스템**

발행되는 메시지는 브로커의 파일 시스템에 저장

- 토픽 파티션 별 로그 세그먼트(Log Segment)에 메세지 저장

브로커가 토픽 파티션의 메세지를 저장하고 있다.

- 브로커가 토픽 파티션의 레플리카를 가지고 있다.
- 브로커가 토픽 파티션의 상태(State)를 가지고 있다.

하지만 상태를 자동으로 옮기지 않는다.

브로커가 가지고 있는 레플리카를 다른 브로커로 옮기지 않고 운영자가 관리해야한다. 브로커 하나 죽으면 수동으로 옮겨야된다.

**클라우드 환경의 특징**

필요한 리소스를 원하는 만큼 구성하기 쉽다. 대신 추적/예방하기 까다롭다.

**실제 이슈**

특정 브로커의 갑작스러운 종료 → 클러스터의 일시적 성능 저하 발생

원인은 EC2 하드웨어 문제여서 추적하기 힘들었다.

브로커가 죽으면 모든 작업이 중단되고 운영자입장에서는 원인 파악해야되고 클라이언트에 영향이 없는지 확인하고 레플리카도 새로 옮겨주는 후속 작업이 필요하다.

**우아한형제들 카프카**

클러스터 27개, 브로커 162대, 파티션 2400개 

- 메세지 수신(푸시)
- 라이더 배차
- 로그, 이벤트 데이터 분석

### **클라우드 환경에서 늘어나는 카프카를 운영하는 방법**

**이슈 1. 단일 주키퍼 클러스터**

초기에는 하나의 주키퍼 클러스터에 여러 카프카 클러스터를 구성

갈수록 등록되는 클러스터가 증가 주키퍼 의존도 증가 

주키퍼 죽으면 전체 서비스 마비

→ **주키퍼 클러스터 분리 1:1 구조로 해결**

**이슈 2. 업데이트 난이도 증가**

재시작해야 설정하는 Read-only 설정이 필요하기도 하고 브로커를 하나씩 껐다 키는 롤링 업데이트 방법으로는 증가하는 클러스터(브로커)를 감당할 수가 없음.

**롤링 업데이트 한계**

단순 브로커가 많아서 껏다키는 문제보다는 작동중인 브로커를 껏다 켜야되고 복제는 잘 되었는지 클라이언트 이슈는 없는지 다음 진행해도 되는지에 대한 고려가 필요하기 때문이다.

**클라우드 환경**

언제 인스턴스가 실패할지 모르는 클라우드 환경에서 롤링 업데이트중 다른 인스턴스에 이슈가 생긴다면 일시적인 다운타임 발생

**이슈 2. 해결**

1. 클라우드 환경의 장점을 이용하여 기존 브로커의 수만큼 업데이트된 새로운 브로커를 추가한다.
2. 기존 브로커에 있던 레플리카를 신규 브로커로 옮긴다.(상태 이동)
3. 기존 브로커를 제거한다.
4. 결과적으로 클러스터에는 업데이트된 브로커만 구성되게 된다.

트래픽이 있는 프로세스를 종료하지 않고 안정적이게 업데이트 가능

브로커가 많아 질수록 쉽고 간단해지고 

**이슈 3. 카프카 스트림즈 상태 관리**

스트리밍 집계를 위해 사용중인데 상태 정보를 로컬DB와 토픽에 저장한다. 만약 저장 도중 브로커가 꺼지거나 네트워크 이슈가 생기면 상태가 깨져버린다. 

**실제 이슈**

네트워크 통신 문제로 브로커 세션 만료되서 스트림즈에 상태 반영이 정상적으로 이루어지지않아 서비스에 문제가 생김

**이슈 3. 개선**

카프카 스트림즈 [reset.sh](http://reset.sh) 스크립트를 이용해서 복구. 상태가 깨진 이전 시점으로 이동해서 스트림즈 애플리케이션은 Replay. 과정이 중단하고 다시 실행해야되서 아직 고민중

**reference**
[우아한형제들](https://www.youtube.com/watch?v=XyuqoWUCdGA)
